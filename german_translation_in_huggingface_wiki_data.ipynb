{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30746,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "german translation in huggingface wiki data",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aleenakjames/German-Translation-using-LLMs/blob/main/german_translation_in_huggingface_wiki_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Installing all the required libraries**"
      ],
      "metadata": {
        "id": "Hs3xXQkhUKmL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community nltk==3.5 sacrebleu sacremoses"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-07-24T05:30:48.87003Z",
          "iopub.execute_input": "2024-07-24T05:30:48.870373Z",
          "iopub.status.idle": "2024-07-24T05:31:14.249625Z",
          "shell.execute_reply.started": "2024-07-24T05:30:48.870346Z",
          "shell.execute_reply": "2024-07-24T05:31:14.248603Z"
        },
        "trusted": true,
        "id": "DHi-RfWfUKmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Libraries and Imports**"
      ],
      "metadata": {
        "id": "5Z8kvvE5UKmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import (Language, RecursiveCharacterTextSplitter)\n",
        "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast, MarianMTModel, MarianTokenizer\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from datasets import load_metric, load_dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import torch"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-24T05:31:14.251659Z",
          "iopub.execute_input": "2024-07-24T05:31:14.251964Z",
          "iopub.status.idle": "2024-07-24T05:31:21.877086Z",
          "shell.execute_reply.started": "2024-07-24T05:31:14.251936Z",
          "shell.execute_reply": "2024-07-24T05:31:21.876248Z"
        },
        "trusted": true,
        "id": "moYnnDINUKmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loading preprocessed wikipedia data from huggingface**"
      ],
      "metadata": {
        "id": "Blq3IuVyUKmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"wikipedia\", language=\"de\", date=\"20220301\")\n",
        "\n",
        "df = pd.DataFrame(dataset['train'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-24T05:31:24.668948Z",
          "iopub.execute_input": "2024-07-24T05:31:24.669539Z",
          "iopub.status.idle": "2024-07-24T05:37:47.623158Z",
          "shell.execute_reply.started": "2024-07-24T05:31:24.6695Z",
          "shell.execute_reply": "2024-07-24T05:37:47.622277Z"
        },
        "trusted": true,
        "id": "ICRN34CJUKma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-24T05:37:52.976488Z",
          "iopub.execute_input": "2024-07-24T05:37:52.976847Z",
          "iopub.status.idle": "2024-07-24T05:37:53.006408Z",
          "shell.execute_reply.started": "2024-07-24T05:37:52.976818Z",
          "shell.execute_reply": "2024-07-24T05:37:53.005484Z"
        },
        "trusted": true,
        "id": "I4HC8tl6UKmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Preprocessing**"
      ],
      "metadata": {
        "id": "WwqxrNR3UKmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = df['text'].tolist()\n",
        "docs = doc[:10]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-24T05:37:55.594885Z",
          "iopub.execute_input": "2024-07-24T05:37:55.595798Z",
          "iopub.status.idle": "2024-07-24T05:37:55.711937Z",
          "shell.execute_reply.started": "2024-07-24T05:37:55.595763Z",
          "shell.execute_reply": "2024-07-24T05:37:55.710664Z"
        },
        "trusted": true,
        "id": "7t9Ie2rUUKme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, len(docs)):\n",
        "    if docs[i] is not None:\n",
        "        docs[i] = str(docs[i]).replace(\"\\n\", \"\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-24T05:37:57.141925Z",
          "iopub.execute_input": "2024-07-24T05:37:57.142309Z",
          "iopub.status.idle": "2024-07-24T05:37:57.147729Z",
          "shell.execute_reply.started": "2024-07-24T05:37:57.142281Z",
          "shell.execute_reply": "2024-07-24T05:37:57.146728Z"
        },
        "trusted": true,
        "id": "ueLUpDErUKmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Inference using different models**\n",
        "* **mBART:** The model can translate directly between any pair of 50 languages. To translate into a target language, the target language id is forced as the first generated token. To force the target language id as the first generated token, pass the forced_bos_token_id parameter to the generate method.\n",
        "* **MarianMT:** The model \"Helsinki-NLP/opus-mt-de-en\" is a neural machine translation model designed specifically for translating text from German (de) to English (en), and it is part of the OPUS-MT project developed by the Helsinki-NLP group.\n",
        "* **Tsmall100:** It is a compact and fast massively multilingual machine translation model covering more than 10K language pairs, that achieves competitive results while being much smaller and faster."
      ],
      "metadata": {
        "id": "-1P6RplLUKmg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Models and Tokenizers\n",
        "models = {\n",
        "    \"MarianMT\": (\"Helsinki-NLP/opus-mt-de-en\", MarianMTModel, MarianTokenizer),\n",
        "    \"mBART\": (\"facebook/mbart-large-50-many-to-many-mmt\", MBartForConditionalGeneration, MBart50TokenizerFast),\n",
        "    \"Tsmall100\": (\"alirezamsh/small100\", AutoModelForSeq2SeqLM, AutoTokenizer)\n",
        "}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-24T05:37:59.524671Z",
          "iopub.execute_input": "2024-07-24T05:37:59.525051Z",
          "iopub.status.idle": "2024-07-24T05:37:59.615131Z",
          "shell.execute_reply.started": "2024-07-24T05:37:59.524996Z",
          "shell.execute_reply": "2024-07-24T05:37:59.613968Z"
        },
        "trusted": true,
        "id": "jmXuyPS4UKmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfdata = pd.DataFrame({})\n",
        "inferenceTime = {}\n",
        "mbart_translated = []\n",
        "tsmall_translated = []\n",
        "marianmt_translated = []"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-24T05:38:01.184324Z",
          "iopub.execute_input": "2024-07-24T05:38:01.184949Z",
          "iopub.status.idle": "2024-07-24T05:38:01.189735Z",
          "shell.execute_reply.started": "2024-07-24T05:38:01.184919Z",
          "shell.execute_reply": "2024-07-24T05:38:01.188759Z"
        },
        "trusted": true,
        "id": "l_JrYwRVUKmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter.from_language(\n",
        "                language=Language.PYTHON, chunk_size=1000, chunk_overlap=50\n",
        "            )"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-24T05:38:02.785525Z",
          "iopub.execute_input": "2024-07-24T05:38:02.785911Z",
          "iopub.status.idle": "2024-07-24T05:38:02.791656Z",
          "shell.execute_reply.started": "2024-07-24T05:38:02.785882Z",
          "shell.execute_reply": "2024-07-24T05:38:02.790605Z"
        },
        "trusted": true,
        "id": "AMQEhj9lUKmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name, (model_checkpoint, model_class, tokenizer_class) in models.items():\n",
        "    # Load model and tokenizer\n",
        "    print(model_name)\n",
        "    model = model_class.from_pretrained(model_checkpoint).to(device)\n",
        "    tokenizer = tokenizer_class.from_pretrained(model_checkpoint)\n",
        "    translated = []\n",
        "    start_time = time.time()\n",
        "    for i in range(0, len(docs)):\n",
        "        docs_split = text_splitter.create_documents([docs[i]])\n",
        "        pretranslated = []\n",
        "        if model_name == \"mBART\":\n",
        "            tokenizer.src_lang = \"de_DE\"\n",
        "            for chunk in docs_split:\n",
        "                encoded_de = tokenizer(chunk.page_content, return_tensors=\"pt\").to(device)\n",
        "                generated_tokens = model.generate(\n",
        "                    **encoded_de,\n",
        "                    forced_bos_token_id=tokenizer.lang_code_to_id[\"en_XX\"]\n",
        "                )\n",
        "                translated_chunk = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
        "                pretranslated.append(translated_chunk[0])\n",
        "            translated_string = \" \".join(pretranslated)\n",
        "            mbart_translated.append(translated_string)\n",
        "        elif model_name == \"Tsmall100\":\n",
        "            for chunk in docs_split:\n",
        "                encoded_de = tokenizer(chunk.page_content, return_tensors=\"pt\").to(device)\n",
        "                generated_tokens = model.generate(**encoded_de)\n",
        "                translated_chunk = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
        "                pretranslated.append(translated_chunk[0])\n",
        "            translated_string = \" \".join(pretranslated)\n",
        "            tsmall_translated.append(translated_string)\n",
        "        else:\n",
        "            for chunk in docs_split:\n",
        "                encoded_de = tokenizer(chunk.page_content, return_tensors=\"pt\").to(device)\n",
        "                generated_tokens = model.generate(**encoded_de)\n",
        "                translated_chunk = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
        "                pretranslated.append(translated_chunk[0])\n",
        "            translated_string = \" \".join(pretranslated)\n",
        "            marianmt_translated.append(translated_string)\n",
        "    if model_name == \"mBART\":\n",
        "        translated_text = mbart_translated\n",
        "    elif model_name == \"Tsmall100\":\n",
        "        translated_text = tsmall_translated\n",
        "    else:\n",
        "        translated_text = marianmt_translated\n",
        "    end_time = time.time()\n",
        "    inference_time = end_time - start_time\n",
        "    inferenceTime[model_name] = inference_time\n",
        "    dfdata[model_name] = translated_text\n",
        "    dfdata.to_csv(\"translation.csv\", index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-24T05:38:04.406456Z",
          "iopub.execute_input": "2024-07-24T05:38:04.406829Z",
          "iopub.status.idle": "2024-07-24T05:59:47.498973Z",
          "shell.execute_reply.started": "2024-07-24T05:38:04.406804Z",
          "shell.execute_reply": "2024-07-24T05:59:47.497952Z"
        },
        "trusted": true,
        "id": "czvl9e0HUKmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfdata = dfdata[:5]\n",
        "dfdata"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-24T10:27:52.452731Z",
          "iopub.execute_input": "2024-07-24T10:27:52.453385Z",
          "iopub.status.idle": "2024-07-24T10:27:52.464042Z",
          "shell.execute_reply.started": "2024-07-24T10:27:52.453354Z",
          "shell.execute_reply": "2024-07-24T10:27:52.463181Z"
        },
        "trusted": true,
        "id": "lVZAanjVUKmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Calculating Scores**\n",
        "**BLEU:** The score evaluates the quality of machine-generated translations by comparing them to reference translations. Weights define the importance of different n-grams in the BLEU score calculation.\n",
        "\n",
        "**TER:** The Translation Edit Rate score measures the number of edits required to change a machine-translated output into one of the reference translations, with a lower score indicating a higher quality translation.\n",
        "\n",
        "**ChrF:** The Character F-score metric is another evaluation metric for machine translation quality, which computes precision and recall over character n-grams, not word n-grams."
      ],
      "metadata": {
        "id": "DK09OXhUUKml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bleu_metric = load_metric('sacrebleu', trust_remote_code=True)\n",
        "ter_metric = load_metric('ter', trust_remote_code=True)\n",
        "chrf_metric = load_metric('chrf', trust_remote_code=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-24T06:12:21.276065Z",
          "iopub.execute_input": "2024-07-24T06:12:21.276766Z",
          "iopub.status.idle": "2024-07-24T06:12:22.417292Z",
          "shell.execute_reply.started": "2024-07-24T06:12:21.276734Z",
          "shell.execute_reply": "2024-07-24T06:12:22.416559Z"
        },
        "trusted": true,
        "id": "uJfKfIGhUKml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Functions to evaluate translations\n",
        "def evaluate_bleu(predictions, references):\n",
        "    return bleu_metric.compute(predictions=predictions, references=[[ref] for ref in references])\n",
        "def evaluate_chrf(predictions, references):\n",
        "    return chrf_metric.compute(predictions=[pred.split() for pred in predictions], references=[[ref.split()] for ref in references])\n",
        "def evaluate_ter(predictions, references):\n",
        "    for i in range(len(predictions)):\n",
        "        length = min(len(predictions[i]), len(references[i]))\n",
        "        predictions[i] = predictions[i][:length]\n",
        "        references[i] = references[i][:length]\n",
        "    return ter_metric.compute(predictions=[pred.split() for pred in predictions], references=[[ref.split()] for ref in references])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-24T06:12:23.674865Z",
          "iopub.execute_input": "2024-07-24T06:12:23.675917Z",
          "iopub.status.idle": "2024-07-24T06:12:23.683786Z",
          "shell.execute_reply.started": "2024-07-24T06:12:23.675881Z",
          "shell.execute_reply": "2024-07-24T06:12:23.682846Z"
        },
        "trusted": true,
        "id": "hPo9TNrcUKmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "keys = list(models.keys())\n",
        "\n",
        "# Calculate all pairwise comparisons\n",
        "for i in range(len(keys)):\n",
        "    for j in range(len(keys)):\n",
        "        if i != j:\n",
        "            print(keys[i],keys[j])\n",
        "            bleu = evaluate_bleu(dfdata[keys[i]], dfdata[keys[j]])\n",
        "            chrf = evaluate_chrf(dfdata[keys[i]], dfdata[keys[j]])\n",
        "            ter = evaluate_ter(dfdata[keys[i]], dfdata[keys[j]])\n",
        "            results[(keys[i], keys[j])] = {\n",
        "                \"BLEU\": bleu,\n",
        "                \"ChrF\": chrf,\n",
        "                \"TER\": ter\n",
        "            }"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-24T10:28:03.301648Z",
          "iopub.execute_input": "2024-07-24T10:28:03.302021Z"
        },
        "trusted": true,
        "id": "QL3vcm5RUKmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model, time_s in inferenceTime.items():\n",
        "        print(f\"Inferece time of {model}: {time_s}\")\n",
        "for (model1, model2), result in results.items():\n",
        "    print(f\"Model: {model1} to {model2}\")\n",
        "    for metric, score in result.items():\n",
        "        print(f\"  {metric}: {score}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-24T13:35:53.70824Z",
          "iopub.execute_input": "2024-07-24T13:35:53.708608Z",
          "iopub.status.idle": "2024-07-24T13:35:53.715006Z",
          "shell.execute_reply.started": "2024-07-24T13:35:53.708577Z",
          "shell.execute_reply": "2024-07-24T13:35:53.714059Z"
        },
        "trusted": true,
        "id": "kgO7TX_6UKmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Visualising the results**"
      ],
      "metadata": {
        "id": "U8z3CSIbUKmn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize dictionaries to hold DataFrames for each metric\n",
        "metrics = ['BLEU', 'TER', 'ChrF']\n",
        "metric_dfs = {metric: pd.DataFrame(index=keys, columns=keys) for metric in metrics}\n",
        "\n",
        "# Populate the DataFrames with the 'score' from each metric's dictionary\n",
        "for (model1, model2), scores in results.items():\n",
        "    for metric in metrics:\n",
        "        metric_dfs[metric].at[model1, model2] = scores[metric]['score']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-24T13:36:04.088986Z",
          "iopub.execute_input": "2024-07-24T13:36:04.089388Z",
          "iopub.status.idle": "2024-07-24T13:36:04.098868Z",
          "shell.execute_reply.started": "2024-07-24T13:36:04.089355Z",
          "shell.execute_reply": "2024-07-24T13:36:04.098052Z"
        },
        "trusted": true,
        "id": "uaSkgfb6UKmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_heatmap(df, title):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(df.astype(float), annot=True, cmap='coolwarm', fmt='.2f')\n",
        "    plt.title(title)\n",
        "    plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-24T13:36:05.945687Z",
          "iopub.execute_input": "2024-07-24T13:36:05.946473Z",
          "iopub.status.idle": "2024-07-24T13:36:05.95138Z",
          "shell.execute_reply.started": "2024-07-24T13:36:05.946443Z",
          "shell.execute_reply": "2024-07-24T13:36:05.950366Z"
        },
        "trusted": true,
        "id": "twN9dNp5UKmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the results for each metric\n",
        "for metric in metrics:\n",
        "    plot_heatmap(metric_dfs[metric], f'{metric} Scores')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-24T13:36:07.844745Z",
          "iopub.execute_input": "2024-07-24T13:36:07.845451Z",
          "iopub.status.idle": "2024-07-24T13:36:08.601186Z",
          "shell.execute_reply.started": "2024-07-24T13:36:07.845416Z",
          "shell.execute_reply": "2024-07-24T13:36:08.600199Z"
        },
        "trusted": true,
        "id": "CmsiTpvsUKmo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qVTwJ8P0UKmp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}